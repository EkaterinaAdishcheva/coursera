{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from statsmodels.stats.weightstats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "Question 4\n",
    "Уровень кальция в крови здоровых молодых женщин равен в среднем 9.5 милиграммам на децилитр и имеет характерное стандартное отклонение 0.4 мг/дл. В сельской больнице Гватемалы для 160 здоровых беременных женщин при первом обращении для ведения беременности был измерен уровень кальция; среднее значение составило 9.57 мг/дл. Можно ли утверждать, что средний уровень кальция в этой популяции отличается от 9.5?\n",
    "\n",
    "Посчитайте достигаемый уровень значимости. Поскольку известны только среднее и дисперсия, а не сама выборка, нельзя использовать стандартные функции критериев — нужно реализовать формулу достигаемого уровня значимости самостоятельно.\n",
    "\n",
    "Округлите ответ до четырёх знаков после десятичной точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026856695507523787"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*(1-stats.norm.cdf(9.57, loc=9.5, scale=0.4/np.sqrt(160)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.0269\n"
     ]
    }
   ],
   "source": [
    "z = (9.57-9.5)/(0.4/np.sqrt(160))\n",
    "p_value = 2*(1-stats.norm.cdf(abs(z)))\n",
    "print('p-value: %.4f' % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "Как вы считаете, это отличие в среднем уровне кальция в крови практически значимо?\n",
    "Да, раз критерий Стьюдента говорит, что отличие значимо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "Имеются данные о стоимости и размерах 53940 бриллиантов:\n",
    "\n",
    "Отделите 25% случайных наблюдений в тестовую выборку с помощью функции sklearn.cross_validation.train_test_split (зафиксируйте random state = 1). На обучающей выборке настройте две регрессионные модели:\n",
    "\n",
    "* линейную регрессию с помощью LinearRegression без параметров\n",
    "* случайный лес из 10 деревьев с помощью RandomForestRegressor с random_state=1.\n",
    "\n",
    "Какая из моделей лучше предсказывает цену бриллиантов? Сделайте предсказания на тестовой выборке, посчитайте модули отклонений предсказаний от истинных цен. Проверьте гипотезу об одинаковом среднем качестве предсказаний, вычислите достигаемый уровень значимости. Отвергается ли гипотеза об одинаковом качестве моделей против двусторонней альтернативы на уровне значимости $\\alpha=0.05$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   carat   53940 non-null  float64\n",
      " 1   depth   53940 non-null  float64\n",
      " 2   table   53940 non-null  float64\n",
      " 3   price   53940 non-null  int64  \n",
      " 4   x       53940 non-null  float64\n",
      " 5   y       53940 non-null  float64\n",
      " 6   z       53940 non-null  float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "diamonds = pd.read_table('diamonds.txt')\n",
    "diamonds.describe()\n",
    "diamonds.head()\n",
    "diamonds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diamonds[['carat', 'depth', 'table', 'x', 'y', 'z']]\n",
    "y = diamonds['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "890.3764004285619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    13485.000000\n",
      "mean       890.376400\n",
      "std       1161.068461\n",
      "min          0.035915\n",
      "25%        208.160385\n",
      "50%        485.297677\n",
      "75%       1098.149270\n",
      "max      18239.846360\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(y_test - y_pred_lr).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "779.7117583558185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=1).fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    13485.000000\n",
      "mean       779.711758\n",
      "std       1113.574813\n",
      "min          0.096000\n",
      "25%        119.340000\n",
      "50%        316.490000\n",
      "75%        962.280000\n",
      "max      13484.020000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(np.abs(y_test - y_pred_rf).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=18.03725974451148, pvalue=6.936823477520982e-72)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(np.abs(y_test - y_pred_lr), np.abs(y_test - y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval: [98.638526, 122.690758]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import CompareMeans, DescrStatsW\n",
    "print (\"95%% confidence interval: [%f, %f]\" % DescrStatsW(np.abs(y_test - y_pred_lr) - np.abs(y_test - y_pred_rf)).tconfint_mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "В одном из выпусков программы \"Разрушители легенд\" проверялось, действительно ли заразительна зевота. В эксперименте участвовало 50 испытуемых, проходивших собеседование на программу. Каждый из них разговаривал с рекрутером; в конце 34 из 50 бесед рекрутер зевал. Затем испытуемых просили подождать решения рекрутера в соседней пустой комнате. \n",
    "\n",
    "Во время ожидания 10 из 34 испытуемых экспериментальной группы и 4 из 16 испытуемых контрольной начали зевать. Таким образом, разница в доле зевающих людей в этих двух группах составила примерно 4.4%. Ведущие заключили, что миф о заразительности зевоты подтверждён. \n",
    "\n",
    "Можно ли утверждать, что доли зевающих в контрольной и экспериментальной группах отличаются статистически значимо? Посчитайте достигаемый уровень значимости при альтернативе заразительности зевоты, округлите до четырёх знаков после десятичной точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_confint_ind(pos_1, n1, pos_2, n2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    \n",
    "    p1 = float(pos_1) / n1\n",
    "    p2 = float(pos_2) / n2 \n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ n1 + p2 * (1 - p2)/ n2)\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ n1 + p2 * (1 - p2)/ n2)\n",
    "    \n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_ind(pos_1, n1, pos_2, n2):\n",
    "    p1 = float(pos_1) / n1\n",
    "    p2 = float(pos_2) / n2 \n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32410186177608225\n",
      "p-value: 0.3729\n"
     ]
    }
   ],
   "source": [
    "pos_1, n1 = 10, 34\n",
    "pos_2, n2 = 4, 16\n",
    "print(proportions_diff_z_stat_ind(pos_1, n1, pos_2, n2))\n",
    "print(\"p-value: %.4f\" % proportions_diff_z_test(proportions_diff_z_stat_ind(pos_1, n1, pos_2, n2), 'greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\n",
    "Имеются данные измерений двухсот швейцарских тысячефранковых банкнот, бывших в обращении в первой половине XX века. Сто из банкнот были настоящими, и сто — поддельными. На рисунке ниже показаны измеренные признаки.\n",
    "\n",
    "Отделите 50 случайных наблюдений в тестовую выборку с помощью функции sklearn.cross_validation.train_test_split (зафиксируйте random state = 1). На оставшихся 150 настройте два классификатора поддельности банкнот:\n",
    "\n",
    "* логистическая регрессия по признакам X_1, X_2, X_3;\n",
    "* логистическая регрессия по признакам X_4, X_5, X_6.\n",
    "\n",
    "Каждым из классификаторов сделайте предсказания меток классов на тестовой выборке. Одинаковы ли доли ошибочных предсказаний двух классификаторов? Проверьте гипотезу, вычислите достигаемый уровень значимости. Введите номер первой значащей цифры (например, если вы получили $5.5\\times10^{-8}$, нужно ввести 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X1      200 non-null    float64\n",
      " 1   X2      200 non-null    float64\n",
      " 2   X3      200 non-null    float64\n",
      " 3   X4      200 non-null    float64\n",
      " 4   X5      200 non-null    float64\n",
      " 5   X6      200 non-null    float64\n",
      " 6   real    200 non-null    int64  \n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 11.1 KB\n"
     ]
    }
   ],
   "source": [
    "banknotes = pd.read_table('banknotes.txt')\n",
    "banknotes.describe()\n",
    "banknotes.head()\n",
    "banknotes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = banknotes[['X1', 'X2', 'X3', 'X4', 'X5', 'X6']]\n",
    "y = banknotes['real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train[['X1', 'X2', 'X3']]\n",
    "X_train_2 = X_train[['X4', 'X5', 'X6']]\n",
    "X_test_1 = X_test[['X1', 'X2', 'X3']]\n",
    "X_test_2 = X_test[['X4', 'X5', 'X6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19999999999999996\n",
      "[1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 1 1 0 1 0 1 0 0 1 1 1 1 1] 24\n"
     ]
    }
   ],
   "source": [
    "lr_1 = LogisticRegression().fit(X_train_1, y_train)\n",
    "y_pred_1 = lr_1.predict(X_test_1)\n",
    "print(1-accuracy_score(y_pred_1, y_test))\n",
    "err_1 = np.array( [1 if y_train.values[i] == y_pred_1[i] else 0 for i in range(len(y_pred_1))] )\n",
    "print(err_1, err_1.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020000000000000018\n",
      "[1 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0\n",
      " 0 1 0 0 0 1 0 0 0 1 0 1 1] 21\n"
     ]
    }
   ],
   "source": [
    "lr_2 = LogisticRegression().fit(X_train_2, y_train)\n",
    "y_pred_2 = lr_2.predict(X_test_2)\n",
    "print(1-accuracy_score(y_pred_2, y_test))\n",
    "err_2 = np.array( [1 if y_train.values[i] == y_pred_2[i] else 0 for i in range(len(y_pred_2))] )\n",
    "print(err_2, err_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_confint_rel(sample1, sample2, alpha = 0.05):\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    sample = list(zip(sample1, sample2))\n",
    "    n = len(sample)\n",
    "        \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    left_boundary = float(f - g) / n  - z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    right_boundary = float(f - g) / n  + z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_rel(sample1, sample2):\n",
    "    sample = list(zip(sample1, sample2))\n",
    "    n = len(sample)\n",
    "    \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    return float(f - g) / np.sqrt(f + g - float((f - g)**2) / n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for a difference between proportions: [-0.056416, 0.176416]\n"
     ]
    }
   ],
   "source": [
    "print(\"95%% confidence interval for a difference between proportions: [%f, %f]\" \\\n",
    "      % proportions_diff_confint_rel(err_1, err_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.312422\n"
     ]
    }
   ],
   "source": [
    "print(\"p-value: %f\" % proportions_diff_z_test(proportions_diff_z_stat_rel(err_1, err_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "Ежегодно более 200000 людей по всему миру сдают стандартизированный экзамен GMAT при поступлении на программы MBA. Средний результат составляет 525 баллов, стандартное отклонение — 100 баллов. \n",
    "\n",
    "Сто студентов закончили специальные подготовительные курсы и сдали экзамен. Средний полученный ими балл — 541.4. Проверьте гипотезу о неэффективности программы против односторонней альтернативы о том, что программа работает. Отвергается ли на уровне значимости 0.05 нулевая гипотеза? Введите достигаемый уровень значимости, округлённый до 4 знаков после десятичной точки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mark = 541.4\n",
    "avg_mark_data = np.ones(100) * avg_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_mark = 525.\n",
    "st_dev = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_test(mean_val, exp_val, st_dev, num):\n",
    "    standard_error = st_dev / np.sqrt(num)\n",
    "    return (mean_val - exp_val) / standard_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_val_greater(z_stat):\n",
    "    return 1 - stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6399999999999977"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_stat = z_test(avg_mark, exp_mark, st_dev, (len(avg_mark_data)))\n",
    "z_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05050258347410397"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val = p_val_greater(z_stat)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mark = 541.5\n",
    "avg_mark_data = np.ones(100) * avg_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.65"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_stat = z_test(avg_mark, exp_mark, st_dev, (len(avg_mark_data)))\n",
    "z_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0494714680336481"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_val = p_val_greater(z_stat)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2\n",
    "##  4\n",
    "Давайте вернёмся к данным выживаемости пациентов с лейкоцитарной лимфомой из видео про критерий знаков:\n",
    "\n",
    "49, 58, 75, 110, 112, 132, 151, 276, 281, 362^*\n",
    " \n",
    "Измерено остаточное время жизни с момента начала наблюдения (в неделях); звёздочка обозначает цензурирование сверху — исследование длилось 7 лет, и остаточное время жизни одного пациента, который дожил до конца наблюдения, неизвестно.\n",
    "\n",
    "Поскольку цензурировано только одно наблюдение, для проверки гипотезы H_0: med X = 200. \n",
    "На этих данных можно использовать критерий знаковых рангов — можно считать, что время дожития последнего пациента в точности равно 362, на ранг этого наблюдения это никак не повлияет. \n",
    "\n",
    "Критерием знаковых рангов проверьте эту гипотезу против двусторонней альтернативы, введите достигаемый уровень значимости, округлённый до четырёх знаков после десятичной точки.\n",
    "\n",
    "Для классификатора используйте solver='liblinear'\n",
    "Укажите для критерия знаковых рангов Вилкоксона mode='approx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_w = np.array([49, 58, 75, 110, 112, 132, 151, 276, 281, 362])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M: 17, p-value: 0.284503\n"
     ]
    }
   ],
   "source": [
    "print(\"M: %d, p-value: %f\" % wilcoxon(l_w - 200, mode='approx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\n",
    "В ходе исследования влияния лесозаготовки на биоразнообразие лесов острова Борнео собраны данные о количестве видов деревьев в 12 лесах, где вырубка не ведётся:\n",
    "\n",
    "22, 22, 15, 13, 19, 19, 18, 20, 21, 13, 13, 15\n",
    "\n",
    "и в 9 лесах, где идёт вырубка:\n",
    "\n",
    "17, 18, 18, 15, 12, 4, 14, 15, 10.\n",
    "\n",
    "Проверьте гипотезу о равенстве среднего количества видов в двух типах лесов против односторонней альтернативы о снижении биоразнообразия в вырубаемых лесах. Используйте ранговый критерий. Чему равен достигаемый уровень значимости? Округлите до четырёх знаков после десятичной точки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=81.0, pvalue=0.02900499272087373)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_not_cut = np.array([22, 22, 15, 13, 19, 19, 18, 20, 21, 13, 13, 15])\n",
    "forest_cut = np.array([17, 18, 18, 15, 12, 4, 14, 15, 10])\n",
    "\n",
    "stats.mannwhitneyu(forest_not_cut, forest_cut, alternative='greater')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "28 января 1986 года космический шаттл \"Челленджер\" взорвался при взлёте. Семь астронавтов, находившихся на борту, погибли. В ходе расследования причин катастрофы основной версией была неполадка с резиновыми уплотнительными кольцами в соединении с ракетными ускорителями. Для 23 предшествовавших катастрофе полётов \"Челленджера\" известны температура воздуха и появление повреждений хотя бы у одного из уплотнительных колец.\n",
    "\n",
    "С помощью бутстрепа постройте 95% доверительный интервал для разности средних температур воздуха при запусках, когда уплотнительные кольца повреждались, и запусках, когда повреждений не было. Чему равна его ближайшая к нулю граница? Округлите до четырёх знаков после запятой.\n",
    "\n",
    "Чтобы получить в точности такой же доверительный интервал, как у нас:\n",
    "\n",
    "установите random seed = 0 перед первым вызовом функции get_bootstrap_samples, один раз\n",
    "сделайте по 1000 псевдовыборок из каждой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger = pd.read_csv('challenger.txt', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_broken = np.array(challenger[challenger.Incident == 1]['Temperature'])\n",
    "challenger_not_broken = np.array(challenger[challenger.Incident == 0]['Temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples):\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "\n",
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "challenger_broken_bs_mean = np.array(list(map(np.mean, get_bootstrap_samples(challenger_broken, 1000))))\n",
    "challenger_not_broken_bs_mean = np.array(list(map(np.mean, get_bootstrap_samples(challenger_not_broken, 1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for times decrease of infarction: [-8.06457589 -1.45040179]\n"
     ]
    }
   ],
   "source": [
    "print('95%% confidence interval for times decrease of infarction: %s' %\n",
    "      stat_intervals(challenger_broken_bs_mean - challenger_not_broken_bs_mean, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\n",
    "\n",
    "На данных предыдущей задачи проверьте гипотезу об одинаковой средней температуре воздуха в дни, когда уплотнительный кольца повреждались, и дни, когда повреждений не было. Используйте перестановочный критерий и двустороннюю альтернативу. Чему равен достигаемый уровень значимости? Округлите до четырёх знаков после десятичной точки. \n",
    "\n",
    "Чтобы получить такое же значение, как мы:\n",
    "\n",
    "установите random seed = 0;\n",
    "возьмите 10000 перестановок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_ind(sample1, sample2):\n",
    "    return np.mean(sample1) - np.mean(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_combinations(n1, n2, max_combinations):\n",
    "    index = np.arange(n1 + n2)\n",
    "    indices = set([tuple(index)])\n",
    "    for i in range(max_combinations - 1):\n",
    "        np.random.shuffle(index)\n",
    "        indices.add(tuple(index))\n",
    "    return [(index[:n1], index[n1:]) for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_zero_dist_ind(sample1, sample2, max_combinations = None):\n",
    "    joined_sample = np.hstack((sample1, sample2))\n",
    "    n1 = len(sample1)\n",
    "    n = len(joined_sample)\n",
    "    \n",
    "    if max_combinations:\n",
    "        indices = get_random_combinations(n1, len(sample2), max_combinations)\n",
    "    else:\n",
    "        indices = [(list(index), filter(lambda i: i not in index, range(n))) \\\n",
    "                    for index in itertools.combinations(range(n), n1)]\n",
    "    \n",
    "    distr = [joined_sample[list(i[0])].mean() - joined_sample[list(i[1])].mean() \\\n",
    "             for i in indices]\n",
    "    return distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_ind(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_dist_ind(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.0057\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print('p-value: %.4f' % permutation_test(challenger_broken, challenger_not_broken, max_permutations=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
